{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# plot_confusion_matrix is a handy visual tool, added in the latest version of scikit-learn\n",
    "# if you are running an older version, comment out this line and just use confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/music_subset.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_concat_feature(X, feature_name, ohe):\n",
    "    \"\"\"\n",
    "    Helper function for transforming a feature into multiple columns of 1s and 0s. Used\n",
    "    in both training and testing steps.  Takes in the full X dataframe, feature name, \n",
    "    and encoder, and returns the dataframe with that feature transformed into multiple\n",
    "    columns of 1s and 0s\n",
    "    \"\"\"\n",
    "    # create new one-hot encoded df based on the feature\n",
    "    single_feature_df = X[[feature_name]]\n",
    "    feature_array = ohe.transform(single_feature_df).toarray()\n",
    "    ohe_df = pd.DataFrame(feature_array, columns=ohe.categories_[0])\n",
    "    # drop the old feature from X and concat the new one-hot encoded df\n",
    "    X = pd.concat([X, ohe_df], axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_concat_feature_train(X_train_all_features, feature_name):\n",
    "    \"\"\"\n",
    "    Helper function for transforming training data.  It takes in the full X dataframe and\n",
    "    feature name, makes a one-hot encoder, and returns the encoder as well as the dataframe\n",
    "    with that feature transformed into multiple columns of 1s and 0s\n",
    "    \"\"\"\n",
    "    # make a one-hot encoder and fit it to the training data\n",
    "    ohe = OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\")\n",
    "    single_feature_df = X_train_all_features[[feature_name]]\n",
    "    ohe.fit(single_feature_df)\n",
    "    # call helper function that actually encodes the feature and concats it\n",
    "    X_train_all_features = encode_and_concat_feature(X_train_all_features, feature_name, ohe)\n",
    "    return ohe, X_train_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe, df = encode_and_concat_feature_train(df, 'genre')\n",
    "ohe_genres = ohe.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_dict = {0:'C', 1:'C#/Db', 2:'D', \n",
    "            3:'D#/Eb', 4:'E', 5:'F', \n",
    "            6:'F#/Gb', 7:'G', 8:'G#/Ab', \n",
    "            9:'A', 10:'A#/Bb', 11:'B'}\n",
    "df['key']\n",
    "genre_columns = ['classic pop and rock', 'classical', \n",
    "                 'dance and electronica', 'folk', 'hip-hop',\n",
    "                'jazz and blues', 'metal', 'pop', 'punk',\n",
    "                'soul and reggae']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop((['genre', 'title', 'track_id', 'artist_name']+genre_columns), axis=1)\n",
    "track_ids = df['track_id']\n",
    "y = df['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>duration</th>\n",
       "      <th>avg_timbre1</th>\n",
       "      <th>avg_timbre2</th>\n",
       "      <th>avg_timbre3</th>\n",
       "      <th>avg_timbre4</th>\n",
       "      <th>...</th>\n",
       "      <th>var_timbre3</th>\n",
       "      <th>var_timbre4</th>\n",
       "      <th>var_timbre5</th>\n",
       "      <th>var_timbre6</th>\n",
       "      <th>var_timbre7</th>\n",
       "      <th>var_timbre8</th>\n",
       "      <th>var_timbre9</th>\n",
       "      <th>var_timbre10</th>\n",
       "      <th>var_timbre11</th>\n",
       "      <th>var_timbre12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.508735</td>\n",
       "      <td>0.923956</td>\n",
       "      <td>-1.965210</td>\n",
       "      <td>1.048934</td>\n",
       "      <td>0.657427</td>\n",
       "      <td>-0.024294</td>\n",
       "      <td>0.835503</td>\n",
       "      <td>0.420007</td>\n",
       "      <td>0.160998</td>\n",
       "      <td>-0.029910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.651247</td>\n",
       "      <td>-0.959705</td>\n",
       "      <td>-0.709239</td>\n",
       "      <td>-0.606494</td>\n",
       "      <td>-0.987079</td>\n",
       "      <td>-0.675561</td>\n",
       "      <td>-0.828315</td>\n",
       "      <td>-0.910889</td>\n",
       "      <td>-0.651066</td>\n",
       "      <td>-0.965628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.148327</td>\n",
       "      <td>0.737095</td>\n",
       "      <td>-1.965210</td>\n",
       "      <td>-0.348494</td>\n",
       "      <td>-1.521081</td>\n",
       "      <td>-0.476913</td>\n",
       "      <td>0.367161</td>\n",
       "      <td>-1.487053</td>\n",
       "      <td>0.872575</td>\n",
       "      <td>0.429374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061616</td>\n",
       "      <td>-0.526899</td>\n",
       "      <td>-0.737697</td>\n",
       "      <td>-0.626681</td>\n",
       "      <td>-0.403496</td>\n",
       "      <td>-0.407307</td>\n",
       "      <td>-0.237706</td>\n",
       "      <td>-0.590470</td>\n",
       "      <td>-0.560248</td>\n",
       "      <td>-0.386641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.372447</td>\n",
       "      <td>-0.277950</td>\n",
       "      <td>-1.965210</td>\n",
       "      <td>1.328420</td>\n",
       "      <td>-1.521081</td>\n",
       "      <td>-0.729996</td>\n",
       "      <td>-0.572071</td>\n",
       "      <td>-0.998178</td>\n",
       "      <td>0.541128</td>\n",
       "      <td>-0.869605</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.690960</td>\n",
       "      <td>1.054225</td>\n",
       "      <td>-0.416093</td>\n",
       "      <td>-0.446295</td>\n",
       "      <td>-0.324081</td>\n",
       "      <td>-0.273530</td>\n",
       "      <td>0.305110</td>\n",
       "      <td>-0.420348</td>\n",
       "      <td>0.854475</td>\n",
       "      <td>-0.384887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.242391</td>\n",
       "      <td>-0.148903</td>\n",
       "      <td>0.384558</td>\n",
       "      <td>0.489963</td>\n",
       "      <td>0.657427</td>\n",
       "      <td>0.006871</td>\n",
       "      <td>0.200291</td>\n",
       "      <td>0.468720</td>\n",
       "      <td>1.207840</td>\n",
       "      <td>0.053538</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000695</td>\n",
       "      <td>-0.974762</td>\n",
       "      <td>-0.944384</td>\n",
       "      <td>-0.957597</td>\n",
       "      <td>-0.829458</td>\n",
       "      <td>-0.982475</td>\n",
       "      <td>-0.767600</td>\n",
       "      <td>-1.025860</td>\n",
       "      <td>-1.199868</td>\n",
       "      <td>0.124363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.482479</td>\n",
       "      <td>0.539356</td>\n",
       "      <td>0.384558</td>\n",
       "      <td>1.048934</td>\n",
       "      <td>-1.521081</td>\n",
       "      <td>0.462000</td>\n",
       "      <td>-0.045677</td>\n",
       "      <td>-0.107932</td>\n",
       "      <td>0.832519</td>\n",
       "      <td>-0.377376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.778112</td>\n",
       "      <td>-1.180547</td>\n",
       "      <td>-0.062467</td>\n",
       "      <td>-1.243304</td>\n",
       "      <td>-1.040457</td>\n",
       "      <td>-1.165665</td>\n",
       "      <td>0.098408</td>\n",
       "      <td>-1.186592</td>\n",
       "      <td>-1.223835</td>\n",
       "      <td>-0.636719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loudness     tempo  time_signature       key      mode  duration  \\\n",
       "0  0.508735  0.923956       -1.965210  1.048934  0.657427 -0.024294   \n",
       "1  0.148327  0.737095       -1.965210 -0.348494 -1.521081 -0.476913   \n",
       "2 -0.372447 -0.277950       -1.965210  1.328420 -1.521081 -0.729996   \n",
       "3 -0.242391 -0.148903        0.384558  0.489963  0.657427  0.006871   \n",
       "4 -0.482479  0.539356        0.384558  1.048934 -1.521081  0.462000   \n",
       "\n",
       "   avg_timbre1  avg_timbre2  avg_timbre3  avg_timbre4  ...  var_timbre3  \\\n",
       "0     0.835503     0.420007     0.160998    -0.029910  ...    -0.651247   \n",
       "1     0.367161    -1.487053     0.872575     0.429374  ...    -0.061616   \n",
       "2    -0.572071    -0.998178     0.541128    -0.869605  ...    -0.690960   \n",
       "3     0.200291     0.468720     1.207840     0.053538  ...    -1.000695   \n",
       "4    -0.045677    -0.107932     0.832519    -0.377376  ...    -0.778112   \n",
       "\n",
       "   var_timbre4  var_timbre5  var_timbre6  var_timbre7  var_timbre8  \\\n",
       "0    -0.959705    -0.709239    -0.606494    -0.987079    -0.675561   \n",
       "1    -0.526899    -0.737697    -0.626681    -0.403496    -0.407307   \n",
       "2     1.054225    -0.416093    -0.446295    -0.324081    -0.273530   \n",
       "3    -0.974762    -0.944384    -0.957597    -0.829458    -0.982475   \n",
       "4    -1.180547    -0.062467    -1.243304    -1.040457    -1.165665   \n",
       "\n",
       "   var_timbre9  var_timbre10  var_timbre11  var_timbre12  \n",
       "0    -0.828315     -0.910889     -0.651066     -0.965628  \n",
       "1    -0.237706     -0.590470     -0.560248     -0.386641  \n",
       "2     0.305110     -0.420348      0.854475     -0.384887  \n",
       "3    -0.767600     -1.025860     -1.199868      0.124363  \n",
       "4     0.098408     -1.186592     -1.223835     -0.636719  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_columns = X.columns\n",
    "ss = StandardScaler()\n",
    "X = pd.DataFrame(ss.fit_transform(X))\n",
    "X.columns = X_columns\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEDNESDAY (SMOTE artificial sample production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. read in csv (drop unneeded columns, encode artist name)\n",
    "2. perform train test split\n",
    "3. Preprocessing\n",
    "4. Transformations\n",
    "5. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/music_subset.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1).set_index('track_id')\n",
    "df = df.drop('title', axis=1)\n",
    "df = df[df['genre'] != 'classic pop and rock']\n",
    "\n",
    "# df = encode_artist_name(df)\n",
    "df = df.drop('artist_name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('genre', axis=1)\n",
    "y = df['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split with stratified target('genre')\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=2020, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### << PIPELINE STARTS AFTER TRAIN-TEST SPLIT >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# sm = SMOTE()\n",
    "# x_train_resamp, y_train_resamp = sm.fit_resample(x_train, y_train)\n",
    "# x_train_resamp, y_train_resamp = sm.fit_resample(x_train, y_train)\n",
    "# rf_model = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('smote', SMOTE(random_state=2020)),\n",
    "    ('model', RandomForestClassifier(n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('smote',\n",
       "                 SMOTE(k_neighbors=5, n_jobs=None, random_state=2020,\n",
       "                       sampling_strategy='auto')),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26778 26778 8927 8927\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(y_train), len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "# sm = SMOTE()\n",
    "# x_train_resamp, y_train_resamp = sm.fit_resample(x_train, y_train)\n",
    "\n",
    "class SMOTE_Transformer(BaseEstimator):\n",
    "    sm = SMOTE()\n",
    "    def fit(self, X, y):\n",
    "        X_new, y_new = sm.fit_resample(X, y)\n",
    "        return X_new, y_new\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_train_resamp.value_counts(), y_test_resamp.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "rf.fit(x_train_resamp, y_train_resamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 3, 4, 5: perform all preprocessing steps on X_train and fit model\n",
    "# pipe = Pipeline(steps=[\n",
    "#     (\"transform_precip\", PrecipitationTransformer()),\n",
    "#     (\"encode_winter\", ColumnTransformer(transformers=[\n",
    "#         (\"ohe\", OneHotEncoder(sparse=False, handle_unknown=\"ignore\"),\n",
    "#          [\"winter_severity_index\"])\n",
    "#     ], remainder=\"passthrough\"\n",
    "#     )),\n",
    "#     (\"linreg_model\", LinearRegression())\n",
    "# ])\n",
    "# pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### << PIPELINE ENDS HERE >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "            classical       0.99      0.96      0.97      9894\n",
      "dance and electronica       0.95      0.91      0.93      9894\n",
      "                 folk       0.91      1.00      0.96      9894\n",
      "              hip-hop       0.99      0.99      0.99      9894\n",
      "       jazz and blues       0.95      0.93      0.94      9894\n",
      "                metal       0.97      0.97      0.97      9894\n",
      "                  pop       0.94      0.97      0.95      9894\n",
      "                 punk       0.96      0.92      0.94      9894\n",
      "      soul and reggae       0.92      0.93      0.92      9894\n",
      "\n",
      "             accuracy                           0.95     89046\n",
      "            macro avg       0.95      0.95      0.95     89046\n",
      "         weighted avg       0.95      0.95      0.95     89046\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "            classical       0.68      0.79      0.73       469\n",
      "dance and electronica       0.66      0.64      0.65      1234\n",
      "                 folk       0.78      0.76      0.77      3298\n",
      "              hip-hop       0.32      0.32      0.32       108\n",
      "       jazz and blues       0.61      0.57      0.59      1084\n",
      "                metal       0.78      0.76      0.77       526\n",
      "                  pop       0.37      0.46      0.41       404\n",
      "                 punk       0.65      0.63      0.64       800\n",
      "      soul and reggae       0.54      0.60      0.57      1004\n",
      "\n",
      "             accuracy                           0.67      8927\n",
      "            macro avg       0.60      0.61      0.61      8927\n",
      "         weighted avg       0.68      0.67      0.67      8927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train_resamp, rf.predict(x_train_resamp)))\n",
    "print(classification_report(y_test, pipe.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "            classical       0.70      0.78      0.74       469\n",
      "dance and electronica       0.66      0.63      0.64      1234\n",
      "                 folk       0.78      0.76      0.77      3298\n",
      "              hip-hop       0.36      0.38      0.37       108\n",
      "       jazz and blues       0.62      0.57      0.59      1084\n",
      "                metal       0.78      0.76      0.77       526\n",
      "                  pop       0.37      0.46      0.41       404\n",
      "                 punk       0.65      0.63      0.64       800\n",
      "      soul and reggae       0.55      0.60      0.57      1004\n",
      "\n",
      "             accuracy                           0.67      8927\n",
      "            macro avg       0.61      0.62      0.61      8927\n",
      "         weighted avg       0.68      0.67      0.67      8927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "higher score than our Random Forest Classifier using weighted classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features=20,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, min_samples_leaf=2, max_features=20)\n",
    "rf.fit(x_train_resamp, y_train_resamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "            classical       0.85      0.96      0.90      9894\n",
      "dance and electronica       0.92      0.79      0.85      9894\n",
      "                 folk       0.86      0.77      0.82      9894\n",
      "              hip-hop       0.95      1.00      0.97      9894\n",
      "       jazz and blues       0.91      0.85      0.88      9894\n",
      "                metal       0.90      0.98      0.94      9894\n",
      "                  pop       0.95      0.98      0.96      9894\n",
      "                 punk       0.90      0.91      0.90      9894\n",
      "      soul and reggae       0.93      0.95      0.94      9894\n",
      "\n",
      "             accuracy                           0.91     89046\n",
      "            macro avg       0.91      0.91      0.91     89046\n",
      "         weighted avg       0.91      0.91      0.91     89046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train_resamp, rf.predict(x_train_resamp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "            classical       0.48      0.91      0.63       469\n",
      "dance and electronica       0.85      0.60      0.71      1234\n",
      "                 folk       0.88      0.72      0.79      3298\n",
      "              hip-hop       0.42      0.89      0.57       108\n",
      "       jazz and blues       0.72      0.69      0.71      1084\n",
      "                metal       0.69      0.92      0.79       526\n",
      "                  pop       0.66      0.85      0.74       404\n",
      "                 punk       0.72      0.79      0.75       800\n",
      "      soul and reggae       0.78      0.83      0.80      1004\n",
      "\n",
      "             accuracy                           0.75      8927\n",
      "            macro avg       0.69      0.80      0.72      8927\n",
      "         weighted avg       0.78      0.75      0.75      8927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf.predict(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
